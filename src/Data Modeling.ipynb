{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10969a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installer tous les packages nécaissaires\n",
    "!pip install -r ../requirements.txt\n",
    "\n",
    "#ou bien\n",
    "\n",
    "# !pip install autocorrect\n",
    "# !pip install -U spacy\n",
    "# !python -m spacy download fr_core_news_sm\n",
    "# !pip install pyspellchecker\n",
    "# !pip install keras==2.11.0\n",
    "# !pip install xgboost\n",
    "# !pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c6b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "import string                              # for string operations\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer  \n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542cdb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "file4 = '../resources/common/data/labled_comments.xlsx'\n",
    "df_labled = pd.read_excel(file4)\n",
    "file5 = 'resources/common/CleanedData/Lematized_Comments.xlsx'\n",
    "df = pd.read_excel (file5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861a2bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment', 'tokens', 'clean_tokens', 'clean_data_noTokenized ',\n",
       "       'clean_data_noTokenized', 'lemmatized_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff8fc7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment', 'score'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labled.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197aa8a",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5183da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "81/81 [==============================] - 3s 12ms/step - loss: 1.7517 - accuracy: 0.3322\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 1.2053 - accuracy: 0.5925\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.8178 - accuracy: 0.7242\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.5852 - accuracy: 0.8108\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.4696 - accuracy: 0.8508\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.3851 - accuracy: 0.8745\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.3284 - accuracy: 0.8970\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.2987 - accuracy: 0.9060\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.2654 - accuracy: 0.9122\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 0.2313 - accuracy: 0.9258\n",
      "2184/2184 [==============================] - 5s 2ms/step\n",
      "Epoch 1/10\n",
      "2265/2265 [==============================] - 29s 13ms/step - loss: 0.0167 - accuracy: 0.9950\n",
      "Epoch 2/10\n",
      "2265/2265 [==============================] - 29s 13ms/step - loss: 0.0122 - accuracy: 0.9956\n",
      "Epoch 3/10\n",
      "2265/2265 [==============================] - 29s 13ms/step - loss: 0.0105 - accuracy: 0.9964\n",
      "Epoch 4/10\n",
      "2265/2265 [==============================] - 30s 13ms/step - loss: 0.0091 - accuracy: 0.9967\n",
      "Epoch 5/10\n",
      "2265/2265 [==============================] - 31s 14ms/step - loss: 0.0073 - accuracy: 0.9975\n",
      "Epoch 6/10\n",
      "2265/2265 [==============================] - 29s 13ms/step - loss: 0.0068 - accuracy: 0.9977\n",
      "Epoch 7/10\n",
      "2265/2265 [==============================] - 30s 13ms/step - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 8/10\n",
      "2265/2265 [==============================] - 30s 13ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 9/10\n",
      "2265/2265 [==============================] - 31s 14ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 10/10\n",
      "2265/2265 [==============================] - 31s 14ms/step - loss: 0.0031 - accuracy: 0.9988\n",
      "2184/2184 [==============================] - 6s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Étape 1: Entraînez un modèle sur les données étiquetées\n",
    "\n",
    "small_texts = df_labled['comment'].values\n",
    "small_labels = df_labled['score'].values\n",
    "\n",
    "# Encodage des étiquettes\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(small_labels)\n",
    "small_y = to_categorical(encoded_labels)\n",
    "\n",
    "# Tokenization et padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(small_texts)\n",
    "sequences = tokenizer.texts_to_sequences(small_texts)\n",
    "word_index = tokenizer.word_index\n",
    "small_X = pad_sequences(sequences)\n",
    "\n",
    "# Construction du modèle\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, 128, input_length=small_X.shape[1]))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(small_y.shape[1], activation='softmax'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(small_X, small_y, epochs=10, batch_size=32)\n",
    "\n",
    "# Étape 2: Utilisez le modèle pour prédire des étiquettes pour les données non étiquetées\n",
    "\n",
    "# Supposons que df soit votre DataFrame contenant les données non étiquetées\n",
    "# et que la colonne 'lemmatized_tokens' contient les textes déjà nettoyés, tokenisés et lemmatisés\n",
    "\n",
    "# Recombiner les tokens en texte\n",
    "unlabeled_texts = [' '.join(tokens) for tokens in df['lemmatized_tokens'].values]\n",
    "unlabeled_sequences = tokenizer.texts_to_sequences(unlabeled_texts)\n",
    "unlabeled_X = pad_sequences(unlabeled_sequences, maxlen=small_X.shape[1])\n",
    "\n",
    "# Prédiction\n",
    "predictions = model.predict(unlabeled_X)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "# Étape 3: Combinez les données étiquetées originales avec les données auto-étiquetées\n",
    "combined_texts = np.concatenate((small_texts, unlabeled_texts))\n",
    "combined_labels = np.concatenate((small_labels, predicted_labels))\n",
    "\n",
    "# Encodage des étiquettes combinées\n",
    "encoded_combined_labels = label_encoder.transform(combined_labels)\n",
    "combined_y = to_categorical(encoded_combined_labels)\n",
    "\n",
    "# Tokenization et padding des textes combinés\n",
    "combined_sequences = tokenizer.texts_to_sequences(combined_texts)\n",
    "combined_X = pad_sequences(combined_sequences, maxlen=small_X.shape[1])\n",
    "\n",
    "# Étape 4: Ré-entraînez le modèle sur le nouvel ensemble de données combiné\n",
    "model.fit(combined_X, combined_y, epochs=10, batch_size=32)\n",
    "# Préparer les données de la grande dataset pour la prédiction\n",
    "# Comme précédemment mentionné, 'lemmatized_tokens' contient les textes déjà nettoyés, tokenisés et lemmatisés\n",
    "large_unlabeled_texts = [' '.join(tokens) for tokens in df['lemmatized_tokens'].values]\n",
    "large_unlabeled_sequences = tokenizer.texts_to_sequences(large_unlabeled_texts)\n",
    "large_unlabeled_X = pad_sequences(large_unlabeled_sequences, maxlen=small_X.shape[1])\n",
    "\n",
    "# Utiliser le modèle pour prédire les étiquettes de la grande dataset\n",
    "large_predictions = model.predict(large_unlabeled_X)\n",
    "\n",
    "# Convertir les prédictions en étiquettes lisibles\n",
    "large_predicted_labels = np.argmax(large_predictions, axis=1)\n",
    "large_predicted_labels = label_encoder.inverse_transform(large_predicted_labels)\n",
    "\n",
    "# Ajouter les étiquettes prédites à la grande dataset\n",
    "df['predicted_score_lstm'] = large_predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b332bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f49fd",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning with TfidfVectorizer and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbb2893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données étiquetées\n",
    "small_texts = df_labled['comment'].values\n",
    "small_labels = df_labled['score'].values\n",
    "\n",
    "# Création d'un modèle - pipeline TF-IDF suivi d'un Naive Bayes\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Entraînement du modèle avec les données étiquetées\n",
    "model.fit(small_texts, small_labels)\n",
    "\n",
    "# Prédire sur la grande dataset\n",
    "unlabeled_texts = [' '.join(tokens) for tokens in df['lemmatized_tokens'].values]\n",
    "\n",
    "# Utiliser le modèle pour prédire les étiquettes de la grande dataset\n",
    "large_predicted_labels = model.predict(unlabeled_texts)\n",
    "\n",
    "# Ajouter les étiquettes prédites à la grande dataset\n",
    "df['predicted_score_TfidfVectorizer'] = large_predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5abe128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e86fe4",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning with XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ec3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Créer des embeddings de mots avec Word2Vec\n",
    "sentences = [text.split() for text in df_labled['comment'].values]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=300, window=5, min_count=1, workers=4)\n",
    "word2vec_model.save(\"word2vec.model\")\n",
    "\n",
    "# Convertir les textes en représentations vectorielles en utilisant les embeddings de mots\n",
    "def text_to_vector(text, model):\n",
    "    words = text.split()\n",
    "    vector = np.zeros(model.vector_size)\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "    return vector / (len(words) + 1e-5)\n",
    "\n",
    "X = np.array([text_to_vector(text, word2vec_model) for text in df_labled['comment'].values])\n",
    "small_labels = df_labled['score'].values\n",
    "\n",
    "# Encodez les étiquettes en valeurs numériques\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(small_labels)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraîner un modèle XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(label_encoder.classes_),\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.01,\n",
    "    'subsample': 0.8\n",
    "}\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100, early_stopping_rounds=10, evals=[(dtest, 'eval')])\n",
    "\n",
    "# Évaluer les performances sur l'ensemble de test\n",
    "y_pred = bst.predict(dtest)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Préparer les données non étiquetées\n",
    "X_unlabeled = np.array([text_to_vector(' '.join(tokens), word2vec_model) for tokens in df['lemmatized_tokens'].values])\n",
    "\n",
    "# Utiliser le modèle pour prédire les étiquettes de la grande dataset\n",
    "d_unlabeled = xgb.DMatrix(X_unlabeled)\n",
    "large_predictions = bst.predict(d_unlabeled)\n",
    "\n",
    "# Convertir les prédictions en étiquettes lisibles\n",
    "large_predicted_labels = label_encoder.inverse_transform(large_predictions.astype(int))\n",
    "\n",
    "# Ajouter les étiquettes prédites à la grande dataset\n",
    "df['predicted_score_XGB'] = large_predicted_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ea09f9",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning with H2O AUTOML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca616d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-8.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-8 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-8 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-8 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-8 .h2o-table th,\n",
       "#h2o-table-8 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-8 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-8\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>47 mins 36 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Africa/Lagos</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_msi_leu65e</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>5.688 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.13 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         47 mins 36 secs\n",
       "H2O_cluster_timezone:       Africa/Lagos\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    2 months\n",
       "H2O_cluster_name:           H2O_from_python_msi_leu65e\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    5.688 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.13 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import pandas as pd\n",
    "\n",
    "# Initialise H2O\n",
    "h2o.init()\n",
    "\n",
    "# Vectorisation TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "tfidf_matrix = vectorizer.fit_transform(df_labled['comment'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "# Ajouter les étiquettes de score à la DataFrame\n",
    "tfidf_df['score'] = df_labled['score']\n",
    "\n",
    "# Convertir en H2OFrame\n",
    "data = h2o.H2OFrame(tfidf_df)\n",
    "\n",
    "# Spécifiez les noms des colonnes pour les features et la cible\n",
    "features = vectorizer.get_feature_names()\n",
    "target = \"score\"\n",
    "\n",
    "# Convertir la colonne cible en un facteur\n",
    "data[target] = data[target].asfactor()\n",
    "\n",
    "# Exécuter AutoML\n",
    "aml = H2OAutoML(max_models=10, max_runtime_secs=300, seed=1)\n",
    "aml.train(y=target, x=features, training_frame=data)\n",
    "\n",
    "# Afficher le classement des modèles\n",
    "lb = aml.leaderboard\n",
    "print(lb)\n",
    "\n",
    "# Récupérer le meilleur modèle par son ID\n",
    "best_model = h2o.get_model(aml.leaderboard[0, 'model_id'])\n",
    "\n",
    "# Convertir le grand ensemble de données (df) en H2OFrame\n",
    "large_data = h2o.H2OFrame(df)\n",
    "\n",
    "# Sélectionnez la colonne 'lemmatized_tokens' pour les prédictions\n",
    "new_data = large_data[:, [\"lemmatized_tokens\"]]\n",
    "\n",
    "# Faire des prédictions en utilisant le meilleur modèle\n",
    "predictions = best_model.predict(new_data)\n",
    "\n",
    "# Convertir les prédictions H2OFrame en un DataFrame pandas\n",
    "predictions_df = predictions.as_data_frame()\n",
    "\n",
    "# Créer un DataFrame de sortie avec 'lemmatized_tokens' et 'predicted_score_H2O'\n",
    "output_df = pd.DataFrame({\"lemmatized_comment\": df[\"lemmatized_tokens\"], \"predicted_score_H2O\": predictions_df[\"predict\"]})\n",
    "\n",
    "# Afficher le DataFrame de sortie\n",
    "print(output_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc3d0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment        score\n",
      "0   aussi absorption directement niveau peau dit ...  Réclamation\n",
      "1                 doute plus pour efficacité produit  Réclamation\n",
      "2                       jai réclamé régler situation        Refus\n",
      "3                 jamais reçu échantillon auparavant        Refus\n",
      "4      même sil observe antécédent chéloïde ème jour  Réclamation\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32bc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrire le DataFrame avec les deux colonnes dans un fichier Excel\n",
    "df[['comment', 'predicted_score_lstm','predicted_score_TfidfVectorizer','predicted_score_XGB']].to_excel('resources/dev_labo/data/processed/Comments_Clasification.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739febc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
