{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10969a2a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: autocorrect in c:\\users\\msi\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\msi\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 2)) (3.5.4)\n",
      "Requirement already satisfied: pyspellchecker in c:\\users\\msi\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: keras==2.11.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 4)) (2.11.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\msi\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 5)) (1.0.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\msi\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 6)) (2.11.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\msi\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 7)) (3.7)\n",
      "Requirement already satisfied: stopwords in c:\\users\\msi\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 8)) (1.0.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\msi\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 9)) (1.7.1)\n",
      "Requirement already satisfied: h2o in c:\\users\\msi\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 10)) (3.40.0.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (63.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (2.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (1.10.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (2.28.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (2.4.6)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (4.64.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (5.2.1)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (0.10.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (1.1.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (8.1.10)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (1.23.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (1.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from spacy->-r ../requirements.txt (line 2)) (2.0.7)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 5)) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow->-r ../requirements.txt (line 6)) (2.11.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (23.1.21)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (3.19.6)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (2.11.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (0.30.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (4.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (1.51.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (15.0.6.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nltk->-r ../requirements.txt (line 7)) (2021.11.10)\n",
      "Requirement already satisfied: click in c:\\users\\msi\\anaconda3\\lib\\site-packages (from nltk->-r ../requirements.txt (line 7)) (8.0.4)\n",
      "Requirement already satisfied: future in c:\\users\\msi\\anaconda3\\lib\\site-packages (from h2o->-r ../requirements.txt (line 10)) (0.18.2)\n",
      "Requirement already satisfied: tabulate in c:\\users\\msi\\anaconda3\\lib\\site-packages (from h2o->-r ../requirements.txt (line 10)) (0.8.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy->-r ../requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r ../requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r ../requirements.txt (line 2)) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r ../requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->-r ../requirements.txt (line 2)) (2022.9.14)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r ../requirements.txt (line 2)) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy->-r ../requirements.txt (line 2)) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy->-r ../requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from jinja2->spacy->-r ../requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (2.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (0.4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow->-r ../requirements.txt (line 6)) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "#Installer tous les packages nécaissaires\n",
    "!pip install -r ../requirements.txt\n",
    "\n",
    "#ou bien\n",
    "\n",
    "# !pip install autocorrect\n",
    "# !pip install -U spacy\n",
    "# !python -m spacy download fr_core_news_sm\n",
    "# !pip install pyspellchecker\n",
    "# !pip install keras==2.11.0\n",
    "# !pip install xgboost\n",
    "# !pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a995e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: h2o in c:\\users\\msi\\anaconda3\\lib\\site-packages (3.40.0.4)\n",
      "Requirement already satisfied: tabulate in c:\\users\\msi\\anaconda3\\lib\\site-packages (from h2o) (0.8.10)\n",
      "Requirement already satisfied: future in c:\\users\\msi\\anaconda3\\lib\\site-packages (from h2o) (0.18.2)\n",
      "Requirement already satisfied: requests in c:\\users\\msi\\anaconda3\\lib\\site-packages (from h2o) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests->h2o) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests->h2o) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests->h2o) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\msi\\anaconda3\\lib\\site-packages (from requests->h2o) (1.26.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c6b912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "import string                              # for string operations\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer  \n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542cdb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "file4 = '../resources/common/CleanedData/Lematized_labled_data.xlsx'\n",
    "df_labled = pd.read_excel(file4)\n",
    "file5 = '../resources/common/CleanedData/Lematized_Comments.xlsx'\n",
    "df = pd.read_excel (file5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "861a2bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bon retour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rappel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avoir bon retour produit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69880</th>\n",
       "      <td>insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69881</th>\n",
       "      <td>insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69882</th>\n",
       "      <td>insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69883</th>\n",
       "      <td>insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69884</th>\n",
       "      <td>insistance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69885 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        comment\n",
       "0                    bon retour\n",
       "1                    insistance\n",
       "2                    insistance\n",
       "3                        rappel\n",
       "4      avoir bon retour produit\n",
       "...                         ...\n",
       "69880                insistance\n",
       "69881                insistance\n",
       "69882                insistance\n",
       "69883                insistance\n",
       "69884                insistance\n",
       "\n",
       "[69885 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[['lemmatized_tokens_finale']]\n",
    "df.rename(columns={'lemmatized_tokens_finale': 'comment'}, inplace=True)\n",
    "df['comment'] = df['comment'].apply(lambda x: ' '.join(eval(x)).strip(\"[]'\"))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff8fc7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>produit</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Refus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>echantillon</td>\n",
       "      <td>Refus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cheloide</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>prescrire</td>\n",
       "      <td>Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>prescrire</td>\n",
       "      <td>Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>rappel</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td></td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>prescrire</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          comment         score\n",
       "0                   Réclamation\n",
       "1         produit   Réclamation\n",
       "2                         Refus\n",
       "3     echantillon         Refus\n",
       "4        cheloide   Réclamation\n",
       "...           ...           ...\n",
       "2569    prescrire        Client\n",
       "2570    prescrire        Client\n",
       "2571       rappel  Présentation\n",
       "2572                Réclamation\n",
       "2573    prescrire   Réclamation\n",
       "\n",
       "[2574 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labled = df_labled[['lemmatized_tokens','score']]\n",
    "df_labled.rename(columns={'lemmatized_tokens': 'comment'}, inplace=True)\n",
    "df_labled['comment'] = df_labled['comment'].apply(lambda x: ' '.join(eval(x)).strip(\"[]'\"))\n",
    "df_labled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197aa8a",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f5183da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/14\n",
      "81/81 [==============================] - 3s 5ms/step - loss: 1.7582 - accuracy: 0.4169\n",
      "Epoch 2/14\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.3419 - accuracy: 0.5486\n",
      "Epoch 3/14\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.1887 - accuracy: 0.5979\n",
      "Epoch 4/14\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.1337 - accuracy: 0.6131\n",
      "Epoch 5/14\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.1101 - accuracy: 0.6119\n",
      "Epoch 6/14\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.1013 - accuracy: 0.6200\n",
      "Epoch 7/14\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.0839 - accuracy: 0.6200\n",
      "Epoch 8/14\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.0758 - accuracy: 0.6208\n",
      "Epoch 9/14\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.0687 - accuracy: 0.6255\n",
      "Epoch 10/14\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.0611 - accuracy: 0.6263\n",
      "Epoch 11/14\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 1.0543 - accuracy: 0.6313\n",
      "Epoch 12/14\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 1.0460 - accuracy: 0.6309\n",
      "Epoch 13/14\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 1.0374 - accuracy: 0.6317\n",
      "Epoch 14/14\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.0282 - accuracy: 0.6391\n",
      "2184/2184 [==============================] - 3s 1ms/step\n",
      "Epoch 1/8\n",
      "2265/2265 [==============================] - 12s 5ms/step - loss: 0.0731 - accuracy: 0.9857\n",
      "Epoch 2/8\n",
      "2265/2265 [==============================] - 12s 5ms/step - loss: 0.0653 - accuracy: 0.9866\n",
      "Epoch 3/8\n",
      "2265/2265 [==============================] - 12s 5ms/step - loss: 0.0648 - accuracy: 0.9865\n",
      "Epoch 4/8\n",
      "2265/2265 [==============================] - 12s 5ms/step - loss: 0.0642 - accuracy: 0.9869\n",
      "Epoch 5/8\n",
      "2265/2265 [==============================] - 12s 5ms/step - loss: 0.0635 - accuracy: 0.9870\n",
      "Epoch 6/8\n",
      "2265/2265 [==============================] - 12s 5ms/step - loss: 0.0629 - accuracy: 0.9868\n",
      "Epoch 7/8\n",
      "2265/2265 [==============================] - 12s 5ms/step - loss: 0.0624 - accuracy: 0.9870\n",
      "Epoch 8/8\n",
      "2265/2265 [==============================] - 12s 5ms/step - loss: 0.0621 - accuracy: 0.9872\n",
      "2184/2184 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# Étape 1: Entraînez un modèle sur les données étiquetées\n",
    "\n",
    "small_texts = df_labled['comment'].values\n",
    "small_labels = df_labled['score'].values\n",
    "\n",
    "# Encodage des étiquettes\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(small_labels)\n",
    "small_y = to_categorical(encoded_labels)\n",
    "\n",
    "# Tokenization et padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(small_texts)\n",
    "sequences = tokenizer.texts_to_sequences(small_texts)\n",
    "word_index = tokenizer.word_index\n",
    "small_X = pad_sequences(sequences)\n",
    "\n",
    "# Construction du modèle\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, 128, input_length=small_X.shape[1]))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(small_y.shape[1], activation='softmax'))\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(small_X, small_y, epochs=10, batch_size=32)\n",
    "\n",
    "# Étape 2: Utilisez le modèle pour prédire des étiquettes pour les données non étiquetées\n",
    "\n",
    "# Supposons que df soit votre DataFrame contenant les données non étiquetées\n",
    "# et que la colonne 'lemmatized_tokens' contient les textes déjà nettoyés, tokenisés et lemmatisés\n",
    "\n",
    "# Recombiner les tokens en texte\n",
    "unlabeled_texts = [' '.join(tokens) for tokens in df['comment'].values]\n",
    "unlabeled_sequences = tokenizer.texts_to_sequences(unlabeled_texts)\n",
    "unlabeled_X = pad_sequences(unlabeled_sequences, maxlen=small_X.shape[1])\n",
    "\n",
    "# Prédiction\n",
    "predictions = model.predict(unlabeled_X)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "# Étape 3: Combinez les données étiquetées originales avec les données auto-étiquetées\n",
    "combined_texts = np.concatenate((small_texts, unlabeled_texts))\n",
    "combined_labels = np.concatenate((small_labels, predicted_labels))\n",
    "\n",
    "# Encodage des étiquettes combinées\n",
    "encoded_combined_labels = label_encoder.transform(combined_labels)\n",
    "combined_y = to_categorical(encoded_combined_labels)\n",
    "\n",
    "# Tokenization et padding des textes combinés\n",
    "combined_sequences = tokenizer.texts_to_sequences(combined_texts)\n",
    "combined_X = pad_sequences(combined_sequences, maxlen=small_X.shape[1])\n",
    "\n",
    "# Étape 4: Ré-entraînez le modèle sur le nouvel ensemble de données combiné\n",
    "model.fit(combined_X, combined_y, epochs=10, batch_size=32)\n",
    "# Préparer les données de la grande dataset pour la prédiction\n",
    "# Comme précédemment mentionné, 'lemmatized_tokens' contient les textes déjà nettoyés, tokenisés et lemmatisés\n",
    "large_unlabeled_texts = [' '.join(tokens) for tokens in df['comment'].values]\n",
    "large_unlabeled_sequences = tokenizer.texts_to_sequences(large_unlabeled_texts)\n",
    "large_unlabeled_X = pad_sequences(large_unlabeled_sequences, maxlen=small_X.shape[1])\n",
    "\n",
    "# Utiliser le modèle pour prédire les étiquettes de la grande dataset\n",
    "large_predictions = model.predict(large_unlabeled_X)\n",
    "\n",
    "# Convertir les prédictions en étiquettes lisibles\n",
    "large_predicted_labels = np.argmax(large_predictions, axis=1)\n",
    "large_predicted_labels = label_encoder.inverse_transform(large_predicted_labels)\n",
    "\n",
    "# Ajouter les étiquettes prédites à la grande dataset\n",
    "df['predicted_score_lstm'] = large_predicted_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b332bfde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Refus', 'Refus', 'Refus', ..., 'Refus', 'Refus', 'Refus'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61f49fd",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning with TfidfVectorizer and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cbb2893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données étiquetées\n",
    "small_texts = df_labled['comment'].values\n",
    "small_labels = df_labled['score'].values\n",
    "\n",
    "# Création d'un modèle - pipeline TF-IDF suivi d'un Naive Bayes\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "# Entraînement du modèle avec les données étiquetées\n",
    "model.fit(small_texts, small_labels)\n",
    "\n",
    "# Prédire sur la grande dataset\n",
    "unlabeled_texts = [' '.join(tokens) for tokens in df['comment'].values]\n",
    "\n",
    "# Utiliser le modèle pour prédire les étiquettes de la grande dataset\n",
    "large_predicted_labels = model.predict(unlabeled_texts)\n",
    "\n",
    "# Ajouter les étiquettes prédites à la grande dataset\n",
    "df['predicted_score_TfidfVectorizer'] = large_predicted_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5abe128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted_score_lstm</th>\n",
       "      <th>predicted_score_TfidfVectorizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bon retour</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rappel</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avoir bon retour produit</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69880</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69881</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69882</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69883</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69884</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69885 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        comment predicted_score_lstm  \\\n",
       "0                    bon retour                Refus   \n",
       "1                    insistance                Refus   \n",
       "2                    insistance                Refus   \n",
       "3                        rappel                Refus   \n",
       "4      avoir bon retour produit                Refus   \n",
       "...                         ...                  ...   \n",
       "69880                insistance                Refus   \n",
       "69881                insistance                Refus   \n",
       "69882                insistance                Refus   \n",
       "69883                insistance                Refus   \n",
       "69884                insistance                Refus   \n",
       "\n",
       "      predicted_score_TfidfVectorizer  \n",
       "0                        Présentation  \n",
       "1                        Présentation  \n",
       "2                        Présentation  \n",
       "3                        Présentation  \n",
       "4                        Présentation  \n",
       "...                               ...  \n",
       "69880                    Présentation  \n",
       "69881                    Présentation  \n",
       "69882                    Présentation  \n",
       "69883                    Présentation  \n",
       "69884                    Présentation  \n",
       "\n",
       "[69885 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e86fe4",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning with XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d36ec3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mlogloss:1.93157\n",
      "[1]\teval-mlogloss:1.82451\n",
      "[2]\teval-mlogloss:1.73741\n",
      "[3]\teval-mlogloss:1.66637\n",
      "[4]\teval-mlogloss:1.60677\n",
      "[5]\teval-mlogloss:1.55621\n",
      "[6]\teval-mlogloss:1.51236\n",
      "[7]\teval-mlogloss:1.47316\n",
      "[8]\teval-mlogloss:1.43911\n",
      "[9]\teval-mlogloss:1.41007\n",
      "[10]\teval-mlogloss:1.38487\n",
      "[11]\teval-mlogloss:1.36173\n",
      "[12]\teval-mlogloss:1.34043\n",
      "[13]\teval-mlogloss:1.32378\n",
      "[14]\teval-mlogloss:1.30607\n",
      "[15]\teval-mlogloss:1.29149\n",
      "[16]\teval-mlogloss:1.27829\n",
      "[17]\teval-mlogloss:1.26813\n",
      "[18]\teval-mlogloss:1.25820\n",
      "[19]\teval-mlogloss:1.24982\n",
      "[20]\teval-mlogloss:1.24273\n",
      "[21]\teval-mlogloss:1.23476\n",
      "[22]\teval-mlogloss:1.22911\n",
      "[23]\teval-mlogloss:1.22437\n",
      "[24]\teval-mlogloss:1.22125\n",
      "[25]\teval-mlogloss:1.21760\n",
      "[26]\teval-mlogloss:1.21308\n",
      "[27]\teval-mlogloss:1.21003\n",
      "[28]\teval-mlogloss:1.20762\n",
      "[29]\teval-mlogloss:1.20529\n",
      "[30]\teval-mlogloss:1.20350\n",
      "[31]\teval-mlogloss:1.20146\n",
      "[32]\teval-mlogloss:1.20078\n",
      "[33]\teval-mlogloss:1.19968\n",
      "[34]\teval-mlogloss:1.19894\n",
      "[35]\teval-mlogloss:1.19985\n",
      "[36]\teval-mlogloss:1.19812\n",
      "[37]\teval-mlogloss:1.19807\n",
      "[38]\teval-mlogloss:1.19867\n",
      "[39]\teval-mlogloss:1.19885\n",
      "[40]\teval-mlogloss:1.19862\n",
      "[41]\teval-mlogloss:1.19851\n",
      "[42]\teval-mlogloss:1.19880\n",
      "[43]\teval-mlogloss:1.19927\n",
      "[44]\teval-mlogloss:1.20060\n",
      "[45]\teval-mlogloss:1.20237\n",
      "[46]\teval-mlogloss:1.20402\n",
      "[47]\teval-mlogloss:1.20632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63       141\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.73      0.66      0.69       104\n",
      "           3       0.52      0.75      0.61       142\n",
      "           4       0.29      0.06      0.11        31\n",
      "           5       0.20      0.09      0.12        47\n",
      "           6       0.67      0.57      0.62        14\n",
      "           7       0.74      0.40      0.52        35\n",
      "\n",
      "    accuracy                           0.58       515\n",
      "   macro avg       0.47      0.40      0.41       515\n",
      "weighted avg       0.56      0.58      0.55       515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\msi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\msi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Créer des embeddings de mots avec Word2Vec\n",
    "sentences = [text.split() for text in df_labled['comment'].values]\n",
    "word2vec_model = Word2Vec(sentences, vector_size=300, window=5, min_count=1, workers=4)\n",
    "word2vec_model.save(\"xgbmodel/word2vec.model\")\n",
    "\n",
    "# Convertir les textes en représentations vectorielles en utilisant les embeddings de mots\n",
    "def text_to_vector(text, model):\n",
    "    words = text.split()\n",
    "    vector = np.zeros(model.vector_size)\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "    return vector / (len(words) + 1e-5)\n",
    "\n",
    "X = np.array([text_to_vector(text, word2vec_model) for text in df_labled['comment'].values])\n",
    "small_labels = df_labled['score'].values\n",
    "\n",
    "# Encodez les étiquettes en valeurs numériques\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(small_labels)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraîner un modèle XGBoost\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(label_encoder.classes_),\n",
    "    'max_depth': 8,  # Augmentation de la profondeur\n",
    "    'eta': 0.1,  # Augmentation du taux d'apprentissage\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,  # Ajout d'un hyperparamètre\n",
    "    'min_child_weight': 1  # Ajout d'un hyperparamètre\n",
    "}\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "bst = xgb.train(params, dtrain, num_boost_round=200, early_stopping_rounds=10, evals=[(dtest, 'eval')])\n",
    "\n",
    "# Évaluer les performances sur l'ensemble de test\n",
    "y_pred = bst.predict(dtest)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Préparer les données non étiquetées\n",
    "X_unlabeled = np.array([text_to_vector(' '.join(tokens), word2vec_model) for tokens in df['comment'].values])\n",
    "\n",
    "# Utiliser le modèle pour prédire les étiquettes de la grande dataset\n",
    "d_unlabeled = xgb.DMatrix(X_unlabeled)\n",
    "large_predictions = bst.predict(d_unlabeled)\n",
    "\n",
    "# Convertir les prédictions en étiquettes lisibles\n",
    "large_predicted_labels = label_encoder.inverse_transform(large_predictions.astype(int))\n",
    "\n",
    "# Ajouter les étiquettes prédites à la grande dataset\n",
    "df['predicted_score_XGB'] = large_predicted_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ea09f9",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning with H2O AUTOML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca616d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import h2o\n",
    "# from h2o.automl import H2OAutoML\n",
    "\n",
    "# h2o.init()\n",
    "\n",
    "# # Sélectionner les données étiquetées\n",
    "# small_df = df_labled[['comment', 'score']]\n",
    "\n",
    "# # Convertir le DataFrame en objet H2OFrame\n",
    "# h2o_df_labled = h2o.H2OFrame(small_df)\n",
    "\n",
    "# # Spécifier les noms des colonnes d'entrée et de sortie\n",
    "# x_labled = h2o_df_labled.columns[:-1]  # Colonnes d'entrée (à l'exception de la colonne de l'étiquette)\n",
    "# y_labled = 'score'  # Colonne de l'étiquette\n",
    "\n",
    "# # Convertir la colonne de l'étiquette en facteur (catégorique)\n",
    "# h2o_df_labled[y_labled] = h2o_df_labled[y_labled].asfactor()\n",
    "\n",
    "\n",
    "# # Utiliser H2O AutoML pour entraîner les modèles sur les données étiquetées\n",
    "# automl_labled = H2OAutoML(max_runtime_secs=3600, nfolds=5)  # Spécifier le temps d'exécution maximal en secondes\n",
    "# automl_labled.train(x=x_labled, y=y_labled, training_frame=h2o_df_labled)\n",
    "\n",
    "\n",
    "# # Sélectionner les données non étiquetées\n",
    "# unlabled_df = df[['comment']]\n",
    "\n",
    "# # Convertir le DataFrame en objet H2OFrame\n",
    "# h2o_df_unlabled = h2o.H2OFrame(unlabled_df)\n",
    "\n",
    "# # Faire les prédictions sur les données non étiquetées\n",
    "# predictions_unlabled = automl_labled.predict(h2o_df_unlabled)\n",
    "\n",
    "# # Convertir les prédictions en DataFrame pandas\n",
    "# predictions_unlabled_df = predictions_unlabled.as_data_frame()\n",
    "\n",
    "# # Ajouter les prédictions au DataFrame original\n",
    "# df['predicted_score_H2O_AutoML'] = predictions_unlabled_df['predict'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35e07592",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15008\\3604105201.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Enregistrer le modèle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# import h2o\n",
    "# import os\n",
    "# # Créer un sous-dossier s'il n'existe pas\n",
    "# model_directory = \"h2omodel\"\n",
    "# if not os.path.exists(model_directory):\n",
    "#     os.makedirs(model_directory)\n",
    "# # Enregistrer le modèle\n",
    "# model_path = h2o.save_model(model=best_model, path=model_directory, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7ca5dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 19.0.2+7-44, mixed mode, sharing)\n",
      "  Starting server from C:\\Users\\msi\\anaconda3\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\msi\\AppData\\Local\\Temp\\tmpz5_u00i0\n",
      "  JVM stdout: C:\\Users\\msi\\AppData\\Local\\Temp\\tmpz5_u00i0\\h2o_msi_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\msi\\AppData\\Local\\Temp\\tmpz5_u00i0\\h2o_msi_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Africa/Lagos</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.40.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 2 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_msi_253vys</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>5.957 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.9.13 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       Africa/Lagos\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.40.0.4\n",
       "H2O_cluster_version_age:    2 months and 2 days\n",
       "H2O_cluster_name:           H2O_from_python_msi_253vys\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    5.957 Gb\n",
       "H2O_cluster_total_cores:    12\n",
       "H2O_cluster_allowed_cores:  12\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.9.13 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "drf prediction progress: |███████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\anaconda3\\lib\\site-packages\\h2o\\job.py:83: UserWarning: Test/Validation dataset column 'comment' has levels not trained on: [\"\", \"aller\", \"aller aller prescrire produit produit\", \"aller avoir\", \"aller avoir bon retour\", \"aller avoir prescrire\", \"aller avoir prescrire echantillon\", \"aller bon retour\", \"aller demande echantillon\", \"aller echantillon\", ...2016 not listed..., \"tre satisfait produit demande produit echantillon\", \"tre satisfait produit exclusivement\", \"tre satisfait produit produit\", \"tre satisfait produit rappel\", \"tre satisfait produit retour produit patient\", \"tre satisfait retour produit\", \"tre satisfait retour produit avoir exclusivite\", \"tre satisfait retour produit prescrire\", \"tre satisfait retour produit produit cas avoir exclusivite\", \"tre traitement produit produit\"]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "#Exemple de reutilisation du modele\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# Initialisez H2O\n",
    "h2o.init()\n",
    "\n",
    "# Chargement du modèle sauvegardé\n",
    "chemin_du_modele = \"C:/Users/msi/Desktop/Stage_comments_classification/Comments-Classification-NLP/src/h2omodel/XRT_1_AutoML_1_20230701_11707\"\n",
    "modele_charge = h2o.load_model(chemin_du_modele)\n",
    "\n",
    "# Utilisation du modèle chargé pour faire des prédictions\n",
    "# Assurez-vous que les données sur lesquelles vous voulez faire des prédictions sont au format H2OFrame\n",
    "# Vous pouvez convertir un DataFrame pandas en H2OFrame, comme ceci:\n",
    "\n",
    "donnees_de_prediction = df[['comment']] # Remplacez par les données appropriées\n",
    "h2o_donnees_de_prediction = h2o.H2OFrame(donnees_de_prediction)\n",
    "\n",
    "# Faire des prédictions\n",
    "predictions = modele_charge.predict(h2o_donnees_de_prediction)\n",
    "\n",
    "# Convertir les prédictions en un DataFrame pandas, si nécessaire\n",
    "predictions_df = predictions.as_data_frame()\n",
    "\n",
    "# Ajouter les prédictions au DataFrame original\n",
    "df['predicted_score_H2O_AutoML'] = predictions_df['predict'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a32bc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrire le DataFrame avec les deux colonnes dans un fichier Excel\n",
    "df[['comment', 'predicted_score_lstm','predicted_score_TfidfVectorizer','predicted_score_XGB','predicted_score_H2O_AutoML']].to_excel('../resources/dev_labo/data/processed/Comments_Clasification.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8739febc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>predicted_score_lstm</th>\n",
       "      <th>predicted_score_TfidfVectorizer</th>\n",
       "      <th>predicted_score_XGB</th>\n",
       "      <th>predicted_score_H2O_AutoML</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bon retour</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rappel</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>avoir bon retour produit</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69880</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69881</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69882</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69883</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69884</th>\n",
       "      <td>insistance</td>\n",
       "      <td>Refus</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Présentation</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69885 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        comment predicted_score_lstm  \\\n",
       "0                    bon retour                Refus   \n",
       "1                    insistance                Refus   \n",
       "2                    insistance                Refus   \n",
       "3                        rappel                Refus   \n",
       "4      avoir bon retour produit                Refus   \n",
       "...                         ...                  ...   \n",
       "69880                insistance                Refus   \n",
       "69881                insistance                Refus   \n",
       "69882                insistance                Refus   \n",
       "69883                insistance                Refus   \n",
       "69884                insistance                Refus   \n",
       "\n",
       "      predicted_score_TfidfVectorizer predicted_score_XGB  \\\n",
       "0                        Présentation        Présentation   \n",
       "1                        Présentation        Présentation   \n",
       "2                        Présentation        Présentation   \n",
       "3                        Présentation        Présentation   \n",
       "4                        Présentation        Présentation   \n",
       "...                               ...                 ...   \n",
       "69880                    Présentation        Présentation   \n",
       "69881                    Présentation        Présentation   \n",
       "69882                    Présentation        Présentation   \n",
       "69883                    Présentation        Présentation   \n",
       "69884                    Présentation        Présentation   \n",
       "\n",
       "      predicted_score_H2O_AutoML  \n",
       "0                    Réclamation  \n",
       "1                    Réclamation  \n",
       "2                    Réclamation  \n",
       "3                    Réclamation  \n",
       "4                    Réclamation  \n",
       "...                          ...  \n",
       "69880                Réclamation  \n",
       "69881                Réclamation  \n",
       "69882                Réclamation  \n",
       "69883                Réclamation  \n",
       "69884                Réclamation  \n",
       "\n",
       "[69885 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c0f634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
