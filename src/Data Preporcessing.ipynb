{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac235dfa",
   "metadata": {},
   "source": [
    "\n",
    "# Importing Libraries, Requirements and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installer tous les packages nécaissaires\n",
    "#pip install -r requirements.txt\n",
    "\n",
    "#ou bien\n",
    "\n",
    "# !pip install autocorrect\n",
    "# !pip install -U spacy\n",
    "# !python -m spacy download fr_core_news_sm\n",
    "# !pip install pyspellchecker\n",
    "# !pip install keras==2.11.0\n",
    "# !pip install xgboost\n",
    "# !pip install h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4715e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "import string                              # for string operations\n",
    "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
    "from nltk.stem import PorterStemmer        # module for stemming\n",
    "from nltk.tokenize import TweetTokenizer  \n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "#from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "##from keras.models import Sequential\n",
    "#from keras.layers import Embedding, LSTM, Dense\n",
    "#from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa5c7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chemins des fichiers XLSX\n",
    "file1 = '../resources/common/data/all_raw_comments_cleaning.xlsx'\n",
    "file4 = 'labled_comments.xlsx'\n",
    "\n",
    "# Lecture des fichiers XLSX\n",
    "dfnew_comment = pd.read_excel(file1)\n",
    "df_labled = pd.read_excel(file4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b963061e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aussi absorption directement niveau peau dit ...</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doute plus pour efficacité produit</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jai réclamé régler situation</td>\n",
       "      <td>Refus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jamais reçu échantillon auparavant</td>\n",
       "      <td>Refus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>même sil observe antécédent chéloïde ème jour</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>vient prescrire</td>\n",
       "      <td>Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>vient prescrire moment visite</td>\n",
       "      <td>Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>visite rappel</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>voi cest problème essentiellement gastrique</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>voit pas beaucoup  mai pour ancien oui peut pr...</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment         score\n",
       "0      aussi absorption directement niveau peau dit ...   Réclamation\n",
       "1                    doute plus pour efficacité produit   Réclamation\n",
       "2                          jai réclamé régler situation         Refus\n",
       "3                    jamais reçu échantillon auparavant         Refus\n",
       "4         même sil observe antécédent chéloïde ème jour   Réclamation\n",
       "...                                                 ...           ...\n",
       "2569                                    vient prescrire        Client\n",
       "2570                      vient prescrire moment visite        Client\n",
       "2571                                      visite rappel  Présentation\n",
       "2572        voi cest problème essentiellement gastrique   Réclamation\n",
       "2573  voit pas beaucoup  mai pour ancien oui peut pr...   Réclamation\n",
       "\n",
       "[2574 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c56959d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bon retour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rappel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elle a un bon retour sur produit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69892</th>\n",
       "      <td>Insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69893</th>\n",
       "      <td>Insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69894</th>\n",
       "      <td>Insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69895</th>\n",
       "      <td>Insistance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69896</th>\n",
       "      <td>Insistance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69897 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                comment\n",
       "0                            Bon retour\n",
       "1                            Insistance\n",
       "2                            Insistance\n",
       "3                                Rappel\n",
       "4      Elle a un bon retour sur produit\n",
       "...                                 ...\n",
       "69892                        Insistance\n",
       "69893                        Insistance\n",
       "69894                        Insistance\n",
       "69895                        Insistance\n",
       "69896                        Insistance\n",
       "\n",
       "[69897 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew_comment.drop('Unnamed: 1', axis=1, inplace=True)\n",
    "dfnew_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dace52",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1a6711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                comment\n",
      "0                            Bon retour\n",
      "1                            Insistance\n",
      "2                            Insistance\n",
      "3                                Rappel\n",
      "4      Elle a un bon retour sur produit\n",
      "...                                 ...\n",
      "69892                        Insistance\n",
      "69893                        Insistance\n",
      "69894                        Insistance\n",
      "69895                        Insistance\n",
      "69896                        Insistance\n",
      "\n",
      "[69885 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Vérifiez si le texte est une chaîne\n",
    "    if isinstance(text, str):\n",
    "        # Supprimer le texte de retweet de style ancien \"RT\"\n",
    "        text = re.sub(r'^RT[\\s]+', '', text)\n",
    "        # Supprimer les hyperliens\n",
    "        text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)\n",
    "        # Supprimer les hashtags (seulement supprimer le signe de hash # du mot)\n",
    "        text = re.sub(r'#', '', text)\n",
    "        # Supprimer les dates au format AAAA-MM-JJ\n",
    "        text = re.sub(r'\\b\\d{4}-\\d{2}-\\d{2}\\b', '', text)\n",
    "        # Supprimer l'heure au format HH:MM ou HH:MM:SS\n",
    "        text = re.sub(r'\\b\\d{2}:\\d{2}(:\\d{2})?\\b', '', text)\n",
    "        # Supprimer les caractères spéciaux\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        # Supprimer les lignes vides ou les lignes avec juste un point\n",
    "        text = re.sub(r'^(\\s*\\.?\\s*)$', '', text, flags=re.MULTILINE)\n",
    "        # Supprimer les accents\n",
    "        text = unidecode(text)\n",
    "    else:\n",
    "        # Si le texte est un nombre, convertissez-le en chaîne de caractères\n",
    "        if isinstance(text, (int, float)):\n",
    "            text = str(text)\n",
    "        # Si le texte est une valeur NaN, remplacez-le par une chaîne vide\n",
    "        elif pd.isnull(text):\n",
    "            text = ''\n",
    "    return text.strip()  # Supprimer les espaces blancs en tête ou en queue\n",
    "# Appliquer la fonction à chaque élément du DataFrame\n",
    "dfnew_comment = dfnew_comment.applymap(clean_text)\n",
    "# Remplacer les lignes qui sont juste un point ou une virgule (maintenant une chaîne vide après avoir supprimé les caractères spéciaux) par NaN\n",
    "dfnew_comment.replace(\"\", np.nan, inplace=True)\n",
    "# Supprimer les lignes avec des valeurs NaN\n",
    "dfnew_comment.dropna(subset=['comment'], inplace=True)\n",
    "print(dfnew_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "521dffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                comment\n",
      "0                            Bon retour\n",
      "1                            Insistance\n",
      "2                            Insistance\n",
      "3                                Rappel\n",
      "4      Elle a un bon retour sur produit\n",
      "...                                 ...\n",
      "69892                        Insistance\n",
      "69893                        Insistance\n",
      "69894                        Insistance\n",
      "69895                        Insistance\n",
      "69896                        Insistance\n",
      "\n",
      "[69885 rows x 1 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Renommer dfnew_comment par df\n",
    "df=dfnew_comment\n",
    "print(df)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9839ab",
   "metadata": {},
   "source": [
    "# Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af1c974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     comment\n",
      "0                            \u001b[92mBon retour\n",
      "1                            \u001b[92mInsistance\n",
      "2                            \u001b[92mInsistance\n",
      "3                                \u001b[92mRappel\n",
      "4      \u001b[92mElle a un bon retour sur produit\n",
      "...                                      ...\n",
      "69892                        \u001b[92mInsistance\n",
      "69893                        \u001b[92mInsistance\n",
      "69894                        \u001b[92mInsistance\n",
      "69895                        \u001b[92mInsistance\n",
      "69896                        \u001b[92mInsistance\n",
      "\n",
      "[69885 rows x 1 columns]\n",
      "\u001b[94m\n",
      "\n",
      "DataFrame après tokenisation:\n",
      "                                comment  \\\n",
      "0                            Bon retour   \n",
      "1                            Insistance   \n",
      "2                            Insistance   \n",
      "3                                Rappel   \n",
      "4      Elle a un bon retour sur produit   \n",
      "...                                 ...   \n",
      "69892                        Insistance   \n",
      "69893                        Insistance   \n",
      "69894                        Insistance   \n",
      "69895                        Insistance   \n",
      "69896                        Insistance   \n",
      "\n",
      "                                         tokens  \n",
      "0                                 [bon, retour]  \n",
      "1                                  [insistance]  \n",
      "2                                  [insistance]  \n",
      "3                                      [rappel]  \n",
      "4      [elle, a, un, bon, retour, sur, produit]  \n",
      "...                                         ...  \n",
      "69892                              [insistance]  \n",
      "69893                              [insistance]  \n",
      "69894                              [insistance]  \n",
      "69895                              [insistance]  \n",
      "69896                              [insistance]  \n",
      "\n",
      "[69885 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\033[92m' + df)\n",
    "print('\\033[94m')\n",
    "\n",
    "# instantiate tokenizer class\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "\n",
    "# Tokeniser les textes dans la colonne 'comment'\n",
    "df['tokens'] = df['comment'].apply(tokenizer.tokenize)\n",
    "# Afficher le DataFrame après tokenisation\n",
    "print(\"\\nDataFrame après tokenisation:\")\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7d64946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                comment  \\\n",
      "0                            Bon retour   \n",
      "1                            Insistance   \n",
      "2                            Insistance   \n",
      "3                                Rappel   \n",
      "4      Elle a un bon retour sur produit   \n",
      "...                                 ...   \n",
      "69892                        Insistance   \n",
      "69893                        Insistance   \n",
      "69894                        Insistance   \n",
      "69895                        Insistance   \n",
      "69896                        Insistance   \n",
      "\n",
      "                                         tokens  \n",
      "0                                 [bon, retour]  \n",
      "1                                  [insistance]  \n",
      "2                                  [insistance]  \n",
      "3                                      [rappel]  \n",
      "4      [elle, a, un, bon, retour, sur, produit]  \n",
      "...                                         ...  \n",
      "69892                              [insistance]  \n",
      "69893                              [insistance]  \n",
      "69894                              [insistance]  \n",
      "69895                              [insistance]  \n",
      "69896                              [insistance]  \n",
      "\n",
      "[69885 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d6bb85",
   "metadata": {},
   "source": [
    "# Importing French Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8404624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words\n",
      "\n",
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bedhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords_french = stopwords.words('french')\n",
    "print('Stop words\\n')\n",
    "print(stopwords_french)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e7c1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\n",
      "                                comment  \\\n",
      "0                            Bon retour   \n",
      "1                            Insistance   \n",
      "2                            Insistance   \n",
      "3                                Rappel   \n",
      "4      Elle a un bon retour sur produit   \n",
      "...                                 ...   \n",
      "69892                        Insistance   \n",
      "69893                        Insistance   \n",
      "69894                        Insistance   \n",
      "69895                        Insistance   \n",
      "69896                        Insistance   \n",
      "\n",
      "                                         tokens               clean_tokens  \n",
      "0                                 [bon, retour]              [bon, retour]  \n",
      "1                                  [insistance]               [insistance]  \n",
      "2                                  [insistance]               [insistance]  \n",
      "3                                      [rappel]                   [rappel]  \n",
      "4      [elle, a, un, bon, retour, sur, produit]  [a, bon, retour, produit]  \n",
      "...                                         ...                        ...  \n",
      "69892                              [insistance]               [insistance]  \n",
      "69893                              [insistance]               [insistance]  \n",
      "69894                              [insistance]               [insistance]  \n",
      "69895                              [insistance]               [insistance]  \n",
      "69896                              [insistance]               [insistance]  \n",
      "\n",
      "[69885 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print('\\033[94m')\n",
    "df_clean = []\n",
    "# Parcourir chaque liste de tokens\n",
    "for tokens in df['tokens']:\n",
    "    clean_tokens = []  # Liste pour stocker les tokens nettoyés d'un texte particulier\n",
    "    for word in tokens:  # Parcourir chaque mot dans la liste de tokens\n",
    "        # Vérifier si le mot n'est pas un mot d'arrêt et n'est pas un signe de ponctuation\n",
    "        if word not in stopwords_french and word not in string.punctuation:\n",
    "            clean_tokens.append(word)\n",
    "    # Ajouter les tokens nettoyés de ce texte à la liste df_clean\n",
    "    df_clean.append(clean_tokens)\n",
    "\n",
    "# Vous pouvez maintenant ajouter df_clean comme une nouvelle colonne à votre DataFrame\n",
    "df['clean_tokens'] = df_clean\n",
    "# Afficher le DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d81ea3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                comment  \\\n",
      "0                            Bon retour   \n",
      "1                            Insistance   \n",
      "2                            Insistance   \n",
      "3                                Rappel   \n",
      "4      Elle a un bon retour sur produit   \n",
      "...                                 ...   \n",
      "69892                        Insistance   \n",
      "69893                        Insistance   \n",
      "69894                        Insistance   \n",
      "69895                        Insistance   \n",
      "69896                        Insistance   \n",
      "\n",
      "                                         tokens               clean_tokens  \\\n",
      "0                                 [bon, retour]              [bon, retour]   \n",
      "1                                  [insistance]               [insistance]   \n",
      "2                                  [insistance]               [insistance]   \n",
      "3                                      [rappel]                   [rappel]   \n",
      "4      [elle, a, un, bon, retour, sur, produit]  [a, bon, retour, produit]   \n",
      "...                                         ...                        ...   \n",
      "69892                              [insistance]               [insistance]   \n",
      "69893                              [insistance]               [insistance]   \n",
      "69894                              [insistance]               [insistance]   \n",
      "69895                              [insistance]               [insistance]   \n",
      "69896                              [insistance]               [insistance]   \n",
      "\n",
      "      clean_data_noTokenized  \n",
      "0                 bon retour  \n",
      "1                 insistance  \n",
      "2                 insistance  \n",
      "3                     rappel  \n",
      "4       a bon retour produit  \n",
      "...                      ...  \n",
      "69892             insistance  \n",
      "69893             insistance  \n",
      "69894             insistance  \n",
      "69895             insistance  \n",
      "69896             insistance  \n",
      "\n",
      "[69885 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Créer une nouvelle colonne 'clean_data_noTokenized' en rejoignant les tokens nettoyés en une seule chaîne de caractères\n",
    "df['clean_data_noTokenized'] = df['clean_tokens'].apply(' '.join)\n",
    "# Afficher le DataFrame avec la nouvelle colonne 'clean_data_noTokenized'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89fe675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrire le DataFrame avec les deux colonnes dans un fichier Excel\n",
    "df[['comment', 'clean_data_noTokenized']].to_excel('../resources/common/CleanedData/cleaned_comments.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddc04e7",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f11b050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                comment  \\\n",
      "0                            Bon retour   \n",
      "1                            Insistance   \n",
      "2                            Insistance   \n",
      "3                                Rappel   \n",
      "4      Elle a un bon retour sur produit   \n",
      "...                                 ...   \n",
      "69892                        Insistance   \n",
      "69893                        Insistance   \n",
      "69894                        Insistance   \n",
      "69895                        Insistance   \n",
      "69896                        Insistance   \n",
      "\n",
      "                                         tokens               clean_tokens  \\\n",
      "0                                 [bon, retour]              [bon, retour]   \n",
      "1                                  [insistance]               [insistance]   \n",
      "2                                  [insistance]               [insistance]   \n",
      "3                                      [rappel]                   [rappel]   \n",
      "4      [elle, a, un, bon, retour, sur, produit]  [a, bon, retour, produit]   \n",
      "...                                         ...                        ...   \n",
      "69892                              [insistance]               [insistance]   \n",
      "69893                              [insistance]               [insistance]   \n",
      "69894                              [insistance]               [insistance]   \n",
      "69895                              [insistance]               [insistance]   \n",
      "69896                              [insistance]               [insistance]   \n",
      "\n",
      "      clean_data_noTokenized              lemmatized_tokens  \n",
      "0                 bon retour                  [bon, retour]  \n",
      "1                 insistance                   [insistance]  \n",
      "2                 insistance                   [insistance]  \n",
      "3                     rappel                       [rappel]  \n",
      "4       a bon retour produit  [avoir, bon, retour, produit]  \n",
      "...                      ...                            ...  \n",
      "69892             insistance                   [insistance]  \n",
      "69893             insistance                   [insistance]  \n",
      "69894             insistance                   [insistance]  \n",
      "69895             insistance                   [insistance]  \n",
      "69896             insistance                   [insistance]  \n",
      "\n",
      "[69885 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle de langue français de spaCy\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "# Créer une liste vide pour stocker les tokens lemmatisés\n",
    "df_lemmatized = []\n",
    "\n",
    "# Parcourir chaque liste de tokens\n",
    "for tokens in df_clean:\n",
    "    lemmatized_tokens = []  # Liste pour stocker les tokens lemmatisés d'un texte particulier\n",
    "    for word in tokens:  # Parcourir chaque mot dans la liste de tokens\n",
    "        # Lemmatisation du mot\n",
    "        doc = nlp(word)\n",
    "        lemma = doc[0].lemma_ if doc else word\n",
    "        lemmatized_tokens.append(lemma)  # Ajouter à la liste\n",
    "    # Ajouter les tokens lemmatisés de ce texte à la liste df_lemmatized\n",
    "    df_lemmatized.append(lemmatized_tokens)\n",
    "\n",
    "# Vous pouvez maintenant ajouter df_lemmatized comme une nouvelle colonne à votre DataFrame\n",
    "df['lemmatized_tokens'] = df_lemmatized\n",
    "# Afficher le DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5b5327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Écrir le DataFrame dans un fichier Excel\n",
    "df.to_excel('../resources/common/CleanedData/Lematized_Comments.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202db13",
   "metadata": {},
   "source": [
    "# Most Frequent 50 Lemmatized Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b619b0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rappel: 25278\n",
      "prescrir: 18748\n",
      "produit: 13883\n",
      "prescrire: 10454\n",
      "presentation: 6662\n",
      "prescription: 5145\n",
      "insistance: 4762\n",
      "aller: 4586\n",
      "entrain: 4337\n",
      "exclusivite: 3853\n",
      "bon: 3471\n",
      "retour: 3409\n",
      "avoir: 2255\n",
      "etendue: 1952\n",
      "surface: 1591\n",
      "conseil: 1347\n",
      "prescripteur: 1064\n",
      "fois: 1008\n",
      "quelque: 997\n",
      "promesse: 784\n",
      "demande: 780\n",
      "representation: 762\n",
      "disponible: 626\n",
      "plaie: 617\n",
      "gramme: 584\n",
      "mentionner: 571\n",
      "satisfaire: 523\n",
      "association: 516\n",
      "place: 485\n",
      "traitement: 463\n",
      "patient: 457\n",
      "cheloide: 440\n",
      "relai: 421\n",
      "mise: 401\n",
      "tre: 388\n",
      "satisfait: 385\n",
      "stock: 372\n",
      "surtout: 368\n",
      "echantillon: 367\n",
      "tout: 355\n",
      "cas: 340\n",
      "acte: 320\n",
      "exclusivement: 301\n",
      "engagement: 291\n",
      "bien: 290\n",
      "poste: 269\n",
      "aussi: 249\n",
      "post: 233\n",
      "utilisation: 228\n",
      "comme: 227\n"
     ]
    }
   ],
   "source": [
    "flat_list = [item for sublist in df_lemmatized for item in sublist]\n",
    "# Compter les occurrences de chaque mot\n",
    "word_freq = Counter(flat_list)\n",
    "# Afficher les fréquences de mots\n",
    "for word, count in word_freq.most_common(50):  # Affiche les 50 mots les plus fréquents\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "508f4a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aussi absorption directement niveau peau dit ...</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doute plus pour efficacité produit</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jai réclamé régler situation</td>\n",
       "      <td>Refus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jamais reçu échantillon auparavant</td>\n",
       "      <td>Refus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>même sil observe antécédent chéloïde ème jour</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>vient prescrire</td>\n",
       "      <td>Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>vient prescrire moment visite</td>\n",
       "      <td>Client</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>visite rappel</td>\n",
       "      <td>Présentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>voi cest problème essentiellement gastrique</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>voit pas beaucoup  mai pour ancien oui peut pr...</td>\n",
       "      <td>Réclamation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment         score\n",
       "0      aussi absorption directement niveau peau dit ...   Réclamation\n",
       "1                    doute plus pour efficacité produit   Réclamation\n",
       "2                          jai réclamé régler situation         Refus\n",
       "3                    jamais reçu échantillon auparavant         Refus\n",
       "4         même sil observe antécédent chéloïde ème jour   Réclamation\n",
       "...                                                 ...           ...\n",
       "2569                                    vient prescrire        Client\n",
       "2570                      vient prescrire moment visite        Client\n",
       "2571                                      visite rappel  Présentation\n",
       "2572        voi cest problème essentiellement gastrique   Réclamation\n",
       "2573  voit pas beaucoup  mai pour ancien oui peut pr...   Réclamation\n",
       "\n",
       "[2574 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c2860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
